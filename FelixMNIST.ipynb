{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FelixMNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toomahawkk/Felix-Code/blob/master/FelixMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BL4OVXTJdX7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.optim import lr_scheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import itertools\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from torch.nn import MaxPool2d\n",
        "import chainer.links as L\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.ion()\n",
        "\n",
        "#Transforming the input data (Tensor, Normalize)\n",
        "train_set = torchvision.datasets.MNIST(root='./data/MNIST', train=True, download=True, transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
        "\n",
        "#Setting DataLoader batch size\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 10)\n",
        "torch.set_printoptions(linewidth=120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5lMgrA4oRg-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking how many files & overall label distribution:"
      ]
    },
    {
      "metadata": {
        "id": "OOFj2z64g6oH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(train_set))\n",
        "train_set.train_labels.bincount()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4iV-j_KoFMs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show single images (from train_set):"
      ]
    },
    {
      "metadata": {
        "id": "NQPQM-KPicEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_set))\n",
        "print(type(sample))\n",
        "\n",
        "image, label = sample\n",
        "\n",
        "plt.imshow(image.squeeze(),cmap = 'gray')\n",
        "print(\"label\",label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ENh-dRDuo9aJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show batch images (from train_loader):"
      ]
    },
    {
      "metadata": {
        "id": "bWQ4ApFCo8IE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "\n",
        "image, label = batch\n",
        "\n",
        "grid = torchvision.utils.make_grid(image, nrow=5)\n",
        "\n",
        "plt.imshow(np.transpose(grid,(1,2,0)))\n",
        "print(label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ik1Lb84hxeP7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we create the CNN:"
      ]
    },
    {
      "metadata": {
        "id": "WGiuNc2uxgjb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "          \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 10, kernel_size=5, stride=1),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(10, 20, kernel_size=5, stride=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "          \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(10 * 10 * 20, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = x.view(-1, x.size(1))\n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jr8dG6A7NFEC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1\n",
        "\n",
        "Clearing the Gradients => optimizer.zero_grad()\n",
        "Clear out the gradients accumulated for the parameters of the network before calling loss.backward() and optimizer.step()\n",
        "\n",
        "Step 2\n",
        "\n",
        "Compute the loss => criterion( predicted_target, target)\n",
        "Compute the loss between the predicted value and the target value within the loss function previously defined\n",
        "\n",
        "Step 3\n",
        "\n",
        "Backpropogation => loss.backward()\n",
        "Back-prop all the layers in all the layers of the network\n",
        "\n",
        "Step 4\n",
        "\n",
        "Taking an optimization step => optimizer.step()\n",
        "Update the parameters of the network\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "hy0dU9TeNDe8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AEmsyWIWPL3u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    exp_lr_scheduler.step()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        #print(data.size())\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        #print(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (batch_idx + 1)% 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "                100. * (batch_idx + 1) / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sp62knG4Pw9X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for data, target in data_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        \n",
        "        output = model(data)\n",
        "        loss += F.cross_entropy(output, target, size_average=False).item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        \n",
        "    loss /= len(data_loader.dataset)\n",
        "        \n",
        "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
        "        loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MFHy1nAvQHaz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**RUN** **THE** **CNN**!!!!:"
      ]
    },
    {
      "metadata": {
        "id": "SgKaMMQxQSYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5309
        },
        "outputId": "f1f75321-4d3e-4a1a-9c79-11dec266b23b"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train(epoch)\n",
        "    evaluate(train_loader)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [1000/60000 (2%)]\tLoss: 1.545456\n",
            "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 1.516000\n",
            "Train Epoch: 0 [3000/60000 (5%)]\tLoss: 0.993577\n",
            "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 0.728333\n",
            "Train Epoch: 0 [5000/60000 (8%)]\tLoss: 0.557907\n",
            "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 0.750769\n",
            "Train Epoch: 0 [7000/60000 (12%)]\tLoss: 0.712131\n",
            "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.650096\n",
            "Train Epoch: 0 [9000/60000 (15%)]\tLoss: 0.553767\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.278427\n",
            "Train Epoch: 0 [11000/60000 (18%)]\tLoss: 0.585858\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.422710\n",
            "Train Epoch: 0 [13000/60000 (22%)]\tLoss: 0.477526\n",
            "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 0.456798\n",
            "Train Epoch: 0 [15000/60000 (25%)]\tLoss: 0.347398\n",
            "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.258189\n",
            "Train Epoch: 0 [17000/60000 (28%)]\tLoss: 0.216747\n",
            "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 0.251738\n",
            "Train Epoch: 0 [19000/60000 (32%)]\tLoss: 0.259760\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.173400\n",
            "Train Epoch: 0 [21000/60000 (35%)]\tLoss: 0.163081\n",
            "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.496426\n",
            "Train Epoch: 0 [23000/60000 (38%)]\tLoss: 0.306138\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.147242\n",
            "Train Epoch: 0 [25000/60000 (42%)]\tLoss: 0.285870\n",
            "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.211231\n",
            "Train Epoch: 0 [27000/60000 (45%)]\tLoss: 0.050535\n",
            "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.482445\n",
            "Train Epoch: 0 [29000/60000 (48%)]\tLoss: 0.079173\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.589209\n",
            "Train Epoch: 0 [31000/60000 (52%)]\tLoss: 0.043052\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.301260\n",
            "Train Epoch: 0 [33000/60000 (55%)]\tLoss: 0.064809\n",
            "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.058169\n",
            "Train Epoch: 0 [35000/60000 (58%)]\tLoss: 0.072624\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.132765\n",
            "Train Epoch: 0 [37000/60000 (62%)]\tLoss: 0.082296\n",
            "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.046574\n",
            "Train Epoch: 0 [39000/60000 (65%)]\tLoss: 0.177330\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.740566\n",
            "Train Epoch: 0 [41000/60000 (68%)]\tLoss: 0.023523\n",
            "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.163626\n",
            "Train Epoch: 0 [43000/60000 (72%)]\tLoss: 0.066320\n",
            "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.281926\n",
            "Train Epoch: 0 [45000/60000 (75%)]\tLoss: 0.083757\n",
            "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.102827\n",
            "Train Epoch: 0 [47000/60000 (78%)]\tLoss: 0.104817\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.046603\n",
            "Train Epoch: 0 [49000/60000 (82%)]\tLoss: 0.324552\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.105112\n",
            "Train Epoch: 0 [51000/60000 (85%)]\tLoss: 0.088872\n",
            "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.658936\n",
            "Train Epoch: 0 [53000/60000 (88%)]\tLoss: 0.063115\n",
            "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.282237\n",
            "Train Epoch: 0 [55000/60000 (92%)]\tLoss: 0.088304\n",
            "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.008114\n",
            "Train Epoch: 0 [57000/60000 (95%)]\tLoss: 0.090929\n",
            "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.031312\n",
            "Train Epoch: 0 [59000/60000 (98%)]\tLoss: 0.193028\n",
            "Train Epoch: 0 [60000/60000 (100%)]\tLoss: 0.053018\n",
            "\n",
            "Average loss: 0.0693, Accuracy: 58809/60000 (98.000%)\n",
            "\n",
            "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.214974\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.102385\n",
            "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.074078\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.157960\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.013869\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.265717\n",
            "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.017428\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.157528\n",
            "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.036018\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.058434\n",
            "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.404285\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.074463\n",
            "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.057096\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.415743\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.016800\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.021549\n",
            "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.024557\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.015438\n",
            "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.273817\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.029180\n",
            "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.058085\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.246669\n",
            "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.071719\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.020470\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.087302\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.075424\n",
            "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.031839\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.219301\n",
            "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.006468\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.155282\n",
            "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.013932\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.110582\n",
            "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.064378\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.022190\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.038025\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.323234\n",
            "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.030770\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.008739\n",
            "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.088734\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.412818\n",
            "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.003798\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.092094\n",
            "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.099554\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.025313\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.047580\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.026403\n",
            "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.160002\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.053124\n",
            "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.152380\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.093922\n",
            "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.267682\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.201982\n",
            "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.035641\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.064063\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.091995\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.003401\n",
            "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.040029\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.004715\n",
            "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.052402\n",
            "Train Epoch: 1 [60000/60000 (100%)]\tLoss: 0.067820\n",
            "\n",
            "Average loss: 0.0453, Accuracy: 59197/60000 (98.000%)\n",
            "\n",
            "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.295699\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.141813\n",
            "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.007136\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.031125\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.018980\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.283204\n",
            "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.009709\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.064879\n",
            "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.032960\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.011326\n",
            "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.496798\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.143289\n",
            "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.050039\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.036676\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.010501\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.006276\n",
            "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.009736\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.004670\n",
            "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.065109\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.012042\n",
            "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.014273\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.173964\n",
            "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.137213\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.002300\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.067729\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.057431\n",
            "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.009955\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.331054\n",
            "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.012170\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.130423\n",
            "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.009200\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.189951\n",
            "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.021144\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.017661\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.046935\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.152268\n",
            "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.004730\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.007040\n",
            "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.199040\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.334559\n",
            "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.005245\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.008072\n",
            "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.052006\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.087950\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.017150\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.007658\n",
            "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.068173\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.020746\n",
            "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.097661\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.031294\n",
            "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.029625\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.386612\n",
            "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.011409\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.159836\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.013353\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.007144\n",
            "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.008871\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.005656\n",
            "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.021679\n",
            "Train Epoch: 2 [60000/60000 (100%)]\tLoss: 0.019387\n",
            "\n",
            "Average loss: 0.0368, Accuracy: 59345/60000 (98.000%)\n",
            "\n",
            "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.121085\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.024549\n",
            "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.002246\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.088086\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.004662\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.454140\n",
            "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.005519\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.203984\n",
            "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.020972\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.073317\n",
            "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.732733\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.018345\n",
            "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.019731\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.159524\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.047325\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.027165\n",
            "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.006698\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.003895\n",
            "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.152065\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.007107\n",
            "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.005746\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.217078\n",
            "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.070309\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.003938\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.109030\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.028061\n",
            "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.001943\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.023505\n",
            "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.019551\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.229257\n",
            "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.028318\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.189073\n",
            "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.003746\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.004455\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.003349\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.135982\n",
            "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.002615\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.002337\n",
            "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.301864\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.221233\n",
            "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.002877\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.056626\n",
            "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.027619\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.017505\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.021769\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.009837\n",
            "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.070584\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.017748\n",
            "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.199117\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.009138\n",
            "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.182047\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.175197\n",
            "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.013328\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.028469\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.017178\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.005016\n",
            "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.039076\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.003068\n",
            "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.167916\n",
            "Train Epoch: 3 [60000/60000 (100%)]\tLoss: 0.019421\n",
            "\n",
            "Average loss: 0.0300, Accuracy: 59472/60000 (99.000%)\n",
            "\n",
            "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.105053\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.053287\n",
            "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.004664\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.126640\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.001133\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.033653\n",
            "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.001845\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.262458\n",
            "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.008788\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.002541\n",
            "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.673048\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.133937\n",
            "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.017204\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.016472\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.064293\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.008640\n",
            "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.001848\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.001815\n",
            "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.032412\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.012718\n",
            "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.010165\n",
            "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.404970\n",
            "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.079512\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.001809\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.058872\n",
            "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.010178\n",
            "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.001743\n",
            "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.052040\n",
            "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.003613\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.077596\n",
            "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.009914\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.043533\n",
            "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.007356\n",
            "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.014506\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.002860\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.040727\n",
            "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.003618\n",
            "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.006045\n",
            "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.060971\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.177752\n",
            "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.001898\n",
            "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.031419\n",
            "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.011229\n",
            "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.013777\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.006535\n",
            "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.014509\n",
            "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.059519\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.012363\n",
            "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.038941\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.005843\n",
            "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.067265\n",
            "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.272740\n",
            "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.226865\n",
            "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.146871\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.006404\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.001930\n",
            "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.010944\n",
            "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.004083\n",
            "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.018458\n",
            "Train Epoch: 4 [60000/60000 (100%)]\tLoss: 0.077955\n",
            "\n",
            "Average loss: 0.0269, Accuracy: 59514/60000 (99.000%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}